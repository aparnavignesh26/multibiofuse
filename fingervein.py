import numpy as np
import cv2
import os
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the path to the directory containing the mmcbnu_6000 dataset on Google Drive
dataset_path = '/content/drive/MyDrive/MMCBNU_6000/MMCBNU_6000/MMCBNU_6000'

# Create an instance of ImageDataGenerator with pixel value rescaling
datagen = ImageDataGenerator(rescale=1./255)

# Generate image data batches from a directory
data_generator = datagen.flow_from_directory(
       dataset_path,    # Path to the directory containing images
        target_size=(224, 224),  # Resize images to 224x224 pixels
        batch_size=32,        # Number of images in each batch
        class_mode='binary',  # Binary classification problem (two classes)
        shuffle=False)        # Ensure that images are not shuffled

# Initialize an empty list to store the preprocessed images
preprocessed_images = []

# Loop through each batch of images generated by the data generator
for batch_images in data_generator:
    # Extract the batch of images
    batch_images = batch_images[0]
    
    # Append the batch of images to the list
    preprocessed_images.append(batch_images)
    
    # Break the loop if all images have been processed
    if len(preprocessed_images) * data_generator.batch_size >= data_generator.samples:
        break

# Convert the list of preprocessed images to a NumPy array
preprocessed_dataset = np.vstack(preprocessed_images)

# Save the preprocessed dataset
np.save('preprocessed_dataset.npy', preprocessed_dataset)


