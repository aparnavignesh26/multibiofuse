from google.colab import drive
drive.mount('/content/drive')
import os
data_dir = '/content/drive/MyDrive/MMCBNU_6000'
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rescale=1./255)

data_generator = datagen.flow_from_directory(
        data_dir,
        target_size=(224, 224),
        batch_size=32,
        class_mode='binary',  # Binary classification problem (two classes)
         shuffle=False)        # Ensure that images are not shuffled

# Initialize an empty list to store the preprocessed images
preprocessed_images = []

# Loop through each batch of images generated by the data generator
for batch_images in data_generator:
    # Extract the batch of images
    batch_images = batch_images[0]
    
    # Append the batch of images to the list
    preprocessed_images.append(batch_images)
    
    # Break the loop if all images have been processed
    if len(preprocessed_images) * data_generator.batch_size >= data_generator.samples:
        break

# Convert the list of preprocessed images to a NumPy array
preprocessed_dataset = np.vstack(preprocessed_images)

# Save the preprocessed dataset
np.save('preprocessed_dataset.npy', preprocessed_dataset)

import cv2
# Load the mmcbnu_6000 dataset
dataset = np.load('preprocessed_dataset.npy')
# Convert the dataset to grayscale
grayscale_dataset = np.zeros((dataset.shape[0], dataset.shape[1], dataset.shape[2], 1))
for i in range(dataset.shape[0]):
    for j in range(dataset.shape[1]):
        for k in range(dataset.shape[2]):
            grayscale_dataset[i, j, k, 0] = dataset[i, j, k, 0]
